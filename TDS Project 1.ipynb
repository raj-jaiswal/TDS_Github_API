{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1733,"status":"ok","timestamp":1730694506062,"user":{"displayName":"DIVYA SWAROOP JAISWAL","userId":"08003715602750626669"},"user_tz":-330},"id":"BEEP5kZrKV1U","outputId":"8eac438b-876d-49d1-cde7-d66b4a80d1b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   109  100   109    0     0    561      0 --:--:-- --:--:-- --:--:--   561\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   109  100   109    0     0    539      0 --:--:-- --:--:-- --:--:--   542\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   109  100   109    0     0    559      0 --:--:-- --:--:-- --:--:--   561\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   109  100   109    0     0    505      0 --:--:-- --:--:-- --:--:--   504\n"]}],"source":["!curl -H \"Accept: application/vnd.github+json\" \\\n","     -H \"Authorization: Bearer API_KEY\" \\\n","     \"https://api.github.com/search/users?q=location:Basel+followers:>10&per_page=100&page=1\" > users1.json\n","\n","!curl -H \"Accept: application/vnd.github+json\" \\\n","     -H \"Authorization: Bearer API_KEY\" \\\n","     \"https://api.github.com/search/users?q=location:Basel+followers:>10&per_page=100&page=2\" > users2.json\n","\n","!curl -H \"Accept: application/vnd.github+json\" \\\n","     -H \"Authorization: Bearer API_KEY\" \\\n","     \"https://api.github.com/search/users?q=location:Basel+followers:>10&per_page=100&page=3\" > users3.json\n","\n","!curl -H \"Accept: application/vnd.github+json\" \\\n","     -H \"Authorization: Bearer API_KEY\" \\\n","     \"https://api.github.com/search/users?q=location:Basel+followers:>10&per_page=100&page=4\" > users4.json\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eY3DAivuWTn1"},"outputs":[],"source":["import json\n","import csv\n","\n","# Load JSON data from the file\n","ids=[]\n","with open('users1.json', 'r') as file:\n","    data = json.load(file)\n","\n","for user in data['items']:\n","    ids.append(user['id'])\n","\n","with open('users2.json', 'r') as file:\n","    data = json.load(file)\n","\n","for user in data['items']:\n","    ids.append(user['id'])\n","\n","with open('users3.json', 'r') as file:\n","    data = json.load(file)\n","\n","for user in data['items']:\n","    ids.append(user['id'])\n","\n","with open('users4.json', 'r') as file:\n","    data = json.load(file)\n","\n","for user in data['items']:\n","    ids.append(user['id'])\n","\n","len(ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ioGaJxGZQaK1"},"outputs":[],"source":["import requests\n","import csv\n","import time\n","\n","# GitHub API token (replace with your own)\n","TOKEN = 'YOUR_API_KEY_HERE'\n","\n","# Headers for the API request\n","headers = {\n","    'Accept': 'application/vnd.github+json',\n","    'Authorization': f'Bearer {TOKEN}'\n","}\n","\n","# Output CSV file\n","csv_file = 'github_users.csv'\n","\n","# Define the CSV file for writing\n","with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n","    # Define the CSV writer\n","    writer = csv.writer(csvfile)\n","\n","    # Write the header to the CSV\n","    writer.writerow([\n","        'login', 'name', 'company', 'location', 'email', 'hireable', 'bio',\n","        'public_repos', 'followers', 'following', 'created_at'\n","    ])\n","\n","    # Loop through each user ID in the ids list\n","    i=0\n","    for user_id in ids:\n","        # Make the API request for the current user\n","        response = requests.get(f'https://api.github.com/user/{user_id}', headers=headers)\n","\n","        # Check if the request was successful\n","        if response.status_code == 200:\n","            user_data = response.json()\n","\n","            # Extract relevant fields, with fallback for missing data\n","            login = user_data.get('login', '')\n","            name = user_data.get('name', '')\n","            company = user_data.get('company', '').strip().lstrip('@').upper() if user_data.get('company') else ''\n","            location = user_data.get('location', '')\n","            email = user_data.get('email', '')\n","            hireable = user_data.get('hireable', '')\n","            bio = user_data.get('bio', '')\n","            public_repos = user_data.get('public_repos', 0)\n","            followers = user_data.get('followers', 0)\n","            following = user_data.get('following', 0)\n","            created_at = user_data.get('created_at', '')\n","\n","            # Write the user's data to the CSV file\n","            writer.writerow([\n","                login, name, company, location, email, hireable, bio,\n","                public_repos, followers, following, created_at\n","            ])\n","            i+=1\n","            print(f\"Fetched data for user ID {user_id}, progress {i}/{len(ids)}\")\n","        else:\n","            print(f\"Failed to fetch data for user ID {user_id}: {response.status_code}\")\n","\n","        # To avoid hitting rate limits, it's a good idea to add a short delay between requests\n","        time.sleep(1)\n","\n","print(f\"Data written to {csv_file}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hR8ozpwt44m8"},"outputs":[],"source":["import requests\n","import csv\n","import time\n","\n","TOKEN = 'YOUR_API_KEY_HERE'\n","# Headers for the API request\n","headers = {\n","    'Accept': 'application/vnd.github+json',\n","    'Authorization': f'Bearer {TOKEN}'\n","}\n","\n","# Output CSV file\n","csv_file = 'github_repos_limited.csv'\n","\n","# Define the CSV file for writing\n","with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n","    # Define the CSV writer\n","    writer = csv.writer(csvfile)\n","\n","    # Write the header to the CSV\n","    writer.writerow([\n","        'login', 'full_name', 'created_at', 'stargazers_count', 'watchers_count',\n","        'language', 'has_projects', 'has_wiki', 'license_name'\n","    ])\n","\n","    # Loop through each user ID in the ids list\n","    i=0\n","    for user_id in ids:\n","        i+=1\n","        page = 1\n","        total_repos_fetched = 0\n","\n","        while total_repos_fetched < 500:\n","            # Make the API request for the current user repositories (up to 100 per page)\n","            response = requests.get(\n","                f'https://api.github.com/user/{user_id}/repos?sort=pushed&per_page=100&page={page}',\n","                headers=headers\n","            )\n","\n","            # Check if the request was successful\n","            if response.status_code == 200:\n","                repos = response.json()\n","\n","                # If there are no more repositories, break the loop\n","                if not repos:\n","                    break\n","\n","                for repo in repos:\n","                    # Extract relevant repository details\n","                    full_name = repo.get('full_name', '')\n","                    created_at = repo.get('created_at', '')\n","                    stargazers_count = repo.get('stargazers_count', 0)\n","                    watchers_count = repo.get('watchers_count', 0)\n","                    language = repo.get('language', '')\n","                    has_projects = repo.get('has_projects', False)\n","                    has_wiki = repo.get('has_wiki', False)\n","                    license_info = repo.get('license')\n","                    license_name = license_info['key'] if license_info else ''\n","\n","                    # Make an additional request to get user login since it's not in repo details\n","                    owner_response = requests.get(repo.get('owner', {}).get('url', ''), headers=headers)\n","                    if owner_response.status_code == 200:\n","                        login = owner_response.json().get('login', '')\n","                    else:\n","                        login = ''\n","\n","                    # Write the repository data to the CSV\n","                    writer.writerow([\n","                        login, full_name, created_at, stargazers_count, watchers_count,\n","                        language, has_projects, has_wiki, license_name\n","                    ])\n","\n","                    total_repos_fetched += 1\n","\n","                    # Stop if we have fetched 500 repositories\n","                    if total_repos_fetched >= 500:\n","                        break\n","\n","                print(f\"Fetched {total_repos_fetched} repos for user ID {user_id} (page {page}) user {i}/{len(ids)}\")\n","            else:\n","                print(f\"Failed to fetch repos for user ID {user_id}: {response.status_code}\")\n","                break\n","\n","            # Move to the next page\n","            page += 1\n","\n","            # Add a delay between API calls to avoid rate limits\n","            time.sleep(1)\n","\n","print(f\"Data written to {csv_file}\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMK4CWjOC0BEvL8xrzOkYej"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}